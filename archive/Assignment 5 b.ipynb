{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRkuQOA-ixLt"
   },
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpDU4GkIixLu"
   },
   "source": [
    "This assignment has two parts. In the first part, you will apply the unsupervised learning techniques we discussed in class (dimensionality reduction and clustering) to understand patterns of health inequality in the United States. In the second part, you will apply algorithmic fairness techniques to study a widely used criminal risk prediction algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2JbvWhcixLu"
   },
   "source": [
    "## Part 1: Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beKS9NuyJYxN"
   },
   "source": [
    "1. The data we will be using comes from a paper entitled \"The association between income and life expectancy in the United States, 2001-2014\" (Chetty et al, JAMA 2016). You can download this paper [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4866586/pdf/nihms783419.pdf). Read the abstract and, in a few sentences, summarize the data it uses and the main conclusions it draws. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkCrXwQwJYxO"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SCXAAtYixLv"
   },
   "source": [
    "2. As part of their paper, the authors released numerous aggregated datasets (yay!).  We will be using a dataset (health_ineq_online_table_12) which provides health and inequality metrics for each county. Because there are dozens of metrics, we would like to summarize them in some more compact way using unsupervised learning techniques. \n",
    "\n",
    "Please note that there are many missing values in the dataset. So we need to use the mean values to replace them. \n",
    "\n",
    "Let's start by preprocessing our dataset.\n",
    "\n",
    "a. Remove all columns prior to cur_smoke_q1. Explain why it makes sense to exclude these columns. Then, remove all columns with at least 20% missing values. For the remaining columns, replace missing data in the column with the mean value in the column. Finally, normalize the dataset. Subtract the mean of each column and divide by its standard deviation so it will have mean zero and standard deviation 1 (10 points)\n",
    "\n",
    "b. In a couple sentences, explain why it is important to put columns in this dataset on the same scale by dividing by the standard deviation before applying k-means or PCA. How much does the standard deviation of columns vary prior to standardizing them? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'health_ineq_online_table_12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7be856858b8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'health_ineq_online_table_12.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'health_ineq_online_table_12.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('health_ineq_online_table_12.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(list(df)[0:14], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns with at least 20% missing values\n",
    "\n",
    "df = df.dropna(thresh=0.8*len(df), axis=1)\n",
    "\n",
    "# Replace NaN with column mean\n",
    "\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Normalizing the dataset\n",
    "\n",
    "normalized_df = (df-df.mean())/df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7OdLYaIJYxa"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtqbcj4wixLw"
   },
   "source": [
    "3. Apply PCA to the standardized dataset using sklearn. Print out how much variance is explained by each of the first 10 PCA dimensions, and the total fraction of variance explained. Write a couple sentences interpreting your results. (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA(n_components=10)\n",
    "model.fit(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of variance explained by each component\n",
      "[0.16840755 0.15682395 0.07454074 0.06367072 0.0478859  0.04279045\n",
      " 0.03697806 0.03252388 0.02949627 0.02838289]\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of variance explained by each component\")\n",
    "print(model.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOFbZOAGJYxf"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNNYn_MMJYxf"
   },
   "source": [
    "4. Plot the projection of each county using the first 2 PCA dimensions (ie, make a two-dimensional plot where each point is one county). Comment on any patterns you observe. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqkrz2GIJYxk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKF1vdW-JYxm"
   },
   "source": [
    "5. Interpret the first two PCA dimensions by using the PCA component matrix (which you can get using fitted_model.components_, where fitted_model is your fitted PCA model) and looking at which of the dimensions in the original data the components correlate most strongly with (use the [codebook]('http://www.equality-of-opportunity.org/data/health/health_ineq_online_table_12_readme.pdf') to understand the meanings of different columns) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0U30KejJYxp"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLs4OSAxJYxr"
   },
   "source": [
    "6. Now let's try using k-means to cluster the data using sklearn.cluster.KMeans. We will be clustering data in the low-dimensional space (ie, using the first two PCA dimensions, not the original data). Using one of the methods discussed in the unsupervised learning lecture - for example, visual inspection, plotting the inertia, interpretability of the fitted clusters, etc - select a number of clusters (k). (We strongly suggest you use k<=5 to make it easier to interpret things.) This question is somewhat subjective, which is the point - unsupervised learning is often somewhat subjective - so write a couple sentences defending your method and choice of k. \n",
    "\n",
    "    Interpret the clusters by printing out the size of each cluster, and printing out cluster_centers_ as a dataframe with labeled rows and columns. To make the cluster centers dataframe easier to interpret, use df.style.background_gradient(cmap='RdBu') to color the entries of each cluster. We use the diverging colormap, RdBu, because it will use dramatic red-blue colors for both positive and negative entries, allowing us to see clusters that stand out in both directions. Write a couple sentences summarizing your findings.  (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_U_hL1KJYxu"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jzZreWrixLw"
   },
   "source": [
    "## Part 2: Algorithmic fairness\n",
    "\n",
    "This component of the assignment derives in part, with thanks and permission, from an [assignment](https://web.stanford.edu/class/cs182/assignments/AlgorithmicDecisionMaking-py.zip) in Stanford's CS182: Ethics, Public Policy, and Technological Change. Their assignment, in turn, is based on the journalistic organization ProPublica's [analysis](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) of a criminal risk prediction algorithm which we discussed in the algorithmic fairness lecture. Here, you will be assessing how a classifier designed to predict recidivism -- that is, whether someone will commit a crime in the future -- performs in terms of algorithmic fairness metrics. \n",
    "\n",
    "a. We have split the data for you into a train set (recidivism-training-data) and test set (recidivism-testing-data). You will be training the model on the train set and evaluating model predictions on the test set. (For simplicity, we do not use a validation set in this assignment because we will only be training a single model, so we do not need to select hyperparameters.) Read in the train set and test set, and read the data documentation in the \"Algorithmic Fairness Data Documentation\" file. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('recidivism-training-data.csv')\n",
    "test = pd.read_csv('recidivism-testing-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNKxlUUMUMSL"
   },
   "source": [
    "b. Use the train set to train an (unregularized) logistic regression model using sklearn.linear_model.LogisticRegression with penalty=\"none\"¶, as in the regression assignment. Use the \"recidivism_outcome\" column as the variable you are trying to predict, and all the rest of the features as input features. \n",
    "Please note: there is no need for \"patsy\" or standardization, because the data is already in one-hot form (ie, coded as ones and zeroes) and we are not using regularization. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nZ1EYyky2XGn"
   },
   "outputs": [],
   "source": [
    "targets = train['recidivism_outcome']\n",
    "new_train = train.drop(['recidivism_outcome'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(penalty='none')\n",
    "\n",
    "logreg.fit(new_train, targets)\n",
    "\n",
    "y_train_pred = logreg.predict(new_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj_-3ze7Wy_y"
   },
   "source": [
    "c. Using the test set, report your model's AUC, false positive rate, false negative rate, and the fraction classified as positive, separately for white defendents and for Black defendents. In at least 5 sentences, describe what you observe, and any algorithmic fairness concerns it raises, making reference to algorithmic fairness concepts in class and using quantitative evidence as necessary. Do you believe this algorithm is fair enough to be deployed in practice? Why or why not? (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Defendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Juvenile felony count = 0</th>\n",
       "      <th>Juvenile felony count = 1</th>\n",
       "      <th>Juvenile felony count = 2</th>\n",
       "      <th>Juvenile felony count &gt;= 3</th>\n",
       "      <th>Juvenile misdemeanor count = 0</th>\n",
       "      <th>Juvenile misdemeanor count = 1</th>\n",
       "      <th>Juvenile misdemeanor count = 2</th>\n",
       "      <th>Juvenile misdemeanor count &gt;= 3</th>\n",
       "      <th>Juvenile other offense count = 0</th>\n",
       "      <th>Juvenile other offense count = 1</th>\n",
       "      <th>...</th>\n",
       "      <th>Age &gt; 45</th>\n",
       "      <th>Gender = Female</th>\n",
       "      <th>Gender = Male</th>\n",
       "      <th>Race = Other</th>\n",
       "      <th>Race = Asian</th>\n",
       "      <th>Race = Native American</th>\n",
       "      <th>Race = Caucasian</th>\n",
       "      <th>Race = Hispanic</th>\n",
       "      <th>Race = African American</th>\n",
       "      <th>recidivism_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Juvenile felony count = 0  Juvenile felony count = 1  \\\n",
       "0                          1                          0   \n",
       "1                          1                          0   \n",
       "2                          1                          0   \n",
       "3                          1                          0   \n",
       "4                          1                          0   \n",
       "\n",
       "   Juvenile felony count = 2  Juvenile felony count >= 3  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   Juvenile misdemeanor count = 0  Juvenile misdemeanor count = 1  \\\n",
       "0                               1                               0   \n",
       "1                               1                               0   \n",
       "2                               1                               0   \n",
       "3                               1                               0   \n",
       "4                               1                               0   \n",
       "\n",
       "   Juvenile misdemeanor count = 2  Juvenile misdemeanor count >= 3  \\\n",
       "0                               0                                0   \n",
       "1                               0                                0   \n",
       "2                               0                                0   \n",
       "3                               0                                0   \n",
       "4                               0                                0   \n",
       "\n",
       "   Juvenile other offense count = 0  Juvenile other offense count = 1  ...  \\\n",
       "0                                 1                                 0  ...   \n",
       "1                                 1                                 0  ...   \n",
       "2                                 1                                 0  ...   \n",
       "3                                 0                                 1  ...   \n",
       "4                                 1                                 0  ...   \n",
       "\n",
       "   Age > 45  Gender = Female  Gender = Male  Race = Other  Race = Asian  \\\n",
       "0         0                0              1             0             0   \n",
       "1         0                1              0             0             0   \n",
       "2         0                0              1             0             0   \n",
       "3         0                0              1             0             0   \n",
       "4         0                0              1             0             0   \n",
       "\n",
       "   Race = Native American  Race = Caucasian  Race = Hispanic  \\\n",
       "0                       0                 0                0   \n",
       "1                       0                 0                0   \n",
       "2                       0                 1                0   \n",
       "3                       0                 0                0   \n",
       "4                       0                 0                0   \n",
       "\n",
       "   Race = African American  recidivism_outcome  \n",
       "0                        1                   0  \n",
       "1                        1                   0  \n",
       "2                        0                   0  \n",
       "3                        1                   1  \n",
       "4                        1                   1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_test = test[test['Race = Caucasian'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score of my White test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6631791077738516"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "test_targets = white_test['recidivism_outcome']\n",
    "run_white_test = white_test.drop(['recidivism_outcome'], axis=1)\n",
    "y_test_pred = logreg.predict(run_white_test)\n",
    "\n",
    "print('The AUC score of my White test set:')\n",
    "roc_auc_score(test_targets, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[141 142]\n",
      " [ 77 371]]\n",
      "Outcome values : \n",
      " 141 142 77 371\n"
     ]
    }
   ],
   "source": [
    "# getting confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(test_targets,y_test_pred, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(test_targets,y_test_pred,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 141\n",
    "FP = 77\n",
    "FN = 142\n",
    "TN = 371\n",
    "\n",
    "# apply confusion matrix\n",
    "matrix_test_white = confusion_matrix(variables_test_white, y_test_pred_white, labels=[1,0])\n",
    "\n",
    "# print matrix\n",
    "print('Confusion matrix:')\n",
    "print(matrix_test_white)\n",
    "\n",
    "# get outcome values and reshape if values not same\n",
    "tp, fn, fp, tn = confusion_matrix(variables_test_white, y_test_pred_white, labels=[1,0]).reshape(-1)\n",
    "\n",
    "# print coutomes\n",
    "print(\"Outcome values:\")\n",
    "print(tp, fn, fp, tn)\n",
    "\n",
    "# calculate false positive rate and false negative rate\n",
    "# source: https://www.split.io/glossary/false-positive-rate/\n",
    "\n",
    "fp_rate = fp / (fp + tn)\n",
    "fn_rate = fn / (fn + tp)\n",
    "\n",
    "print('False positive rate: ', fp_rate)\n",
    "print('False negative rate: ', fn_rate)\n",
    "\n",
    "# calculate fraction classified as positive\n",
    "# source: https://www.cuemath.com/numbers/positive-rational-numbers/\n",
    "\n",
    "frac_class_as_positive = (tp + fp) / (tp + fp + fn + tn)\n",
    "print('Fraction classified as positive: ', frac_class_as_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false positive rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.171875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False positive rate: FP / (FP + TN)\n",
    "\n",
    "print('The false positive rate is: ')\n",
    "FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false negative rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5017667844522968"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False negative rate: FN / (FN + TP)\n",
    "\n",
    "print('The false negative rate is: ')\n",
    "FN / (FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction classified as positive is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2982216142270862"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraction classified as positive\n",
    "\n",
    "print('The fraction classified as positive is: ')\n",
    "(TP + FP) / (TP + FP + FN + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Defendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_test = test[test['Race = African American'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score of my Black test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6564179874558617"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "test_targets = black_test['recidivism_outcome']\n",
    "run_black_test = black_test.drop(['recidivism_outcome'], axis=1)\n",
    "y_test_pred = logreg.predict(run_black_test)\n",
    "\n",
    "print('The AUC score of my Black test set:')\n",
    "roc_auc_score(test_targets, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[415 154]\n",
      " [227 318]]\n",
      "Outcome values : \n",
      " 415 154 227 318\n"
     ]
    }
   ],
   "source": [
    "# getting confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(test_targets,y_test_pred, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(test_targets,y_test_pred,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 415\n",
    "FN = 154\n",
    "FP = 227\n",
    "TN = 318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false positive rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41651376146788993"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False positive rate: FP / (FP + TN)\n",
    "\n",
    "print('The false positive rate is: ')\n",
    "FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false negative rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27065026362038663"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False negative rate: FN / (FN + TP)\n",
    "\n",
    "print('The false negative rate is: ')\n",
    "FN / (FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction classified as positive is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5763016157989228"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraction classified as positive\n",
    "\n",
    "print('The fraction classified as positive is: ')\n",
    "(TP + FP) / (TP + FP + FN + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of statistical parity (equal rates across groups), we observe that there is no statistical parity between Whites and Blacks. They have significantly different rates for all 3 measures. Additionally, in terms of predictive equality (equal false positive rates across groups), there is no equality either. Blacks have a much higher false positive rate than Whites, meaning that they are much more likely to be mis-labelled to commit a future crime. Whites also have a much higher false negative rate, meaning that many White defendants are being \"missed\" when they should be predicted for future crime. Both fairness principles are violated here.\n",
    "\n",
    "We believe that this algorithm may still be fair enough to be deployed in practice for two main reasons. Firstly, additional fairness principles could still be explored, such as fairness through blindness (not including race) and using calibration (checking whether equal scores mean the same thing for both groups). Secondly, if this algorithm isn't used, it's still probably the case that the alternative solution (ie. humans or another model) are just as likely to commit bias as well. There is always a trade-off between fairness and maximizing accuracy, and no matter how much the model is finetuned, it will never be able to satisfy ALL of the fairness principles. So therefore, perhaps this model will not be able to improve by much, so we may as well use it since we already have the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cw39sRTXFTy"
   },
   "source": [
    "d. Now train your own model, choosing the features you believe should be used (you are also welcome to use models which are not logistic regression models). Report the model's performance on white and Black defendents, using whatever metrics you believe are appropriate (you are also welcome to evaluate performance on other sensitive/protected groups). Write two paragraphs defending your model design choices, and explaining why you designed the model the way you did. (You're welcome to write two paragraphs explaining why you don't think models should be used in criminal risk prediction at all - this is a reasonable perspective! - but you still need to provide quantitative or non-quantitative evidence to back up your claims.) (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wXEIIwp92XGr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5050 entries, 0 to 5049\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                      Non-Null Count  Dtype\n",
      "---  ------                                      --------------  -----\n",
      " 0   Juvenile felony count = 0                   5050 non-null   int64\n",
      " 1   Juvenile felony count = 1                   5050 non-null   int64\n",
      " 2   Juvenile felony count = 2                   5050 non-null   int64\n",
      " 3   Juvenile felony count >= 3                  5050 non-null   int64\n",
      " 4   Juvenile misdemeanor count = 0              5050 non-null   int64\n",
      " 5   Juvenile misdemeanor count = 1              5050 non-null   int64\n",
      " 6   Juvenile misdemeanor count = 2              5050 non-null   int64\n",
      " 7   Juvenile misdemeanor count >= 3             5050 non-null   int64\n",
      " 8   Juvenile other offense count = 0            5050 non-null   int64\n",
      " 9   Juvenile other offense count = 1            5050 non-null   int64\n",
      " 10  Juvenile other offense count = 2            5050 non-null   int64\n",
      " 11  Juvenile other offense count >= 3           5050 non-null   int64\n",
      " 12  Prior conviction count = 0                  5050 non-null   int64\n",
      " 13  Prior conviction count = 1                  5050 non-null   int64\n",
      " 14  Prior conviction count = 2                  5050 non-null   int64\n",
      " 15  Prior conviction count >= 3                 5050 non-null   int64\n",
      " 16  Charge degree = felony                      5050 non-null   int64\n",
      " 17  Charge degree = misdemeanor                 5050 non-null   int64\n",
      " 18  Charge description = no charge              5050 non-null   int64\n",
      " 19  Charge description = license issue          5050 non-null   int64\n",
      " 20  Charge description = public disturbance     5050 non-null   int64\n",
      " 21  Charge description = negligence             5050 non-null   int64\n",
      " 22  Charge description = drug related           5050 non-null   int64\n",
      " 23  Charge description = alcohol related        5050 non-null   int64\n",
      " 24  Charge description = weapons related        5050 non-null   int64\n",
      " 25  Charge description = evading arrest         5050 non-null   int64\n",
      " 26  Charge description = nonviolent harm        5050 non-null   int64\n",
      " 27  Charge description = theft/fraud/burglary   5050 non-null   int64\n",
      " 28  Charge description = lewdness/prostitution  5050 non-null   int64\n",
      " 29  Charge description = violent crime          5050 non-null   int64\n",
      " 30  Age < 25                                    5050 non-null   int64\n",
      " 31  Age >= 25 and <=45                          5050 non-null   int64\n",
      " 32  Age > 45                                    5050 non-null   int64\n",
      " 33  Gender = Female                             5050 non-null   int64\n",
      " 34  Gender = Male                               5050 non-null   int64\n",
      " 35  Race = Other                                5050 non-null   int64\n",
      " 36  Race = Asian                                5050 non-null   int64\n",
      " 37  Race = Native American                      5050 non-null   int64\n",
      " 38  Race = Caucasian                            5050 non-null   int64\n",
      " 39  Race = Hispanic                             5050 non-null   int64\n",
      " 40  Race = African American                     5050 non-null   int64\n",
      " 41  recidivism_outcome                          5050 non-null   int64\n",
      "dtypes: int64(42)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train = train[['Prior conviction count >= 3', 'Juvenile felony count >= 3', 'Charge degree = felony',\n",
    "                 'Charge description = violent crime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = train['recidivism_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_logreg = LogisticRegression(penalty='none')\n",
    "\n",
    "my_logreg.fit(my_train, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Defendants with my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score of my White test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6339758960121151"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC\n",
    "\n",
    "test_targets = white_test['recidivism_outcome']\n",
    "white_test = white_test[['Prior conviction count >= 3', 'Juvenile felony count >= 3', 'Charge degree = felony',\n",
    "                 'Charge description = violent crime']]\n",
    "y_test_pred = my_logreg.predict(white_test)\n",
    "\n",
    "print('The AUC score of my White test set:')\n",
    "roc_auc_score(test_targets, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[139 144]\n",
      " [100 348]]\n",
      "Outcome values : \n",
      " 139 144 100 348\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(test_targets,y_test_pred, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(test_targets,y_test_pred,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 139\n",
    "FN = 144\n",
    "FP = 100\n",
    "TN = 348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false positive rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22321428571428573"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False positive rate: FP / (FP + TN)\n",
    "\n",
    "print('The false positive rate is: ')\n",
    "FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false negative rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.508833922261484"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False negative rate: FN / (FN + TP)\n",
    "\n",
    "print('The false negative rate is: ')\n",
    "FN / (FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction classified as positive is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32694938440492477"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraction classified as positive\n",
    "\n",
    "print('The fraction classified as positive is: ')\n",
    "(TP + FP) / (TP + FP + FN + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Defendants with my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score of my Black test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6171183953822093"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets = black_test['recidivism_outcome']\n",
    "black_test = black_test[['Prior conviction count >= 3', 'Juvenile felony count >= 3', 'Charge degree = felony',\n",
    "                 'Charge description = violent crime']]\n",
    "y_test_pred = my_logreg.predict(black_test)\n",
    "\n",
    "print('The AUC score of my Black test set:')\n",
    "roc_auc_score(test_targets, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[340 229]\n",
      " [198 347]]\n",
      "Outcome values : \n",
      " 340 229 198 347\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(test_targets,y_test_pred, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(test_targets,y_test_pred,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 340\n",
    "FN = 229\n",
    "FP = 198\n",
    "TN = 347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false positive rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.363302752293578"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False positive rate: FP / (FP + TN)\n",
    "\n",
    "print('The false positive rate is: ')\n",
    "FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false negative rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4024604569420035"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False negative rate: FN / (FN + TP)\n",
    "\n",
    "print('The false negative rate is: ')\n",
    "FN / (FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction classified as positive is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4829443447037702"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraction classified as positive\n",
    "\n",
    "print('The fraction classified as positive is: ')\n",
    "(TP + FP) / (TP + FP + FN + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesizing the results together, we see that:\n",
    "\n",
    "**In the original model that includes all features**\n",
    "\n",
    "WHITE\n",
    "- AUC SCORE: 0.66\n",
    "- False Positive Rate: 0.17\n",
    "- False Negative Rate: 0.50\n",
    "- Fraction classified as Positive: 0.30\n",
    "\n",
    "BLACK\n",
    "- AUC SCORE: 0.66\n",
    "- False Positive Rate: 0.42\n",
    "- False Negative Rate: 0.27\n",
    "- Fraction classified as Positive: 0.58\n",
    "\n",
    "**In my model that excludes race and only includes Prior Conviction Count >= 3, Juvenile Felony Count >= 3, Charge Degree = Felony, and Charge Description = Violent Crime**\n",
    "\n",
    "WHITE\n",
    "- AUC SCORE: 0.63\n",
    "- False Positive Rate: 0.22\n",
    "- False Negative Rate: 0.51\n",
    "- Fraction classified as Positive: 0.33\n",
    "\n",
    "BLACK\n",
    "- AUC SCORE: 0.62\n",
    "- False Positive Rate: 0.36\n",
    "- False Negative Rate: 0.40\n",
    "- Fraction classified as Positive: 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our model, we experimented with excluding race and gender to try and avoid introducing any sort of racial or gender bias in my model. This is \"fairness through blindness\", which may be a weak notion of fairness due to leaving out an important feature, but we wanted to experiment with this since the principles of both statistical parity and predictive equality were not maintained in the original model. We only included highly explanatory features that are directly related to crime: I believe they are highly associated with the possibility of re-committing crimes. This includes a high # of previous crimes (ie. Prior Conviction Count being >= 3), whether or not the defendant committed a lot of crimes when they were young (Juvenile Felony Count >= 3), the severity of the crime (Felony is more severe than Misdemeanour), and whether the crime was violent (Violent Crime). Because the defendant would have to be more courageous to have done a lot of historic and severe crimes, there's a larger chance they'd re-commit again. Also, we decided not to include the Counts that are <= 3 because we believe that defendants deserve a second or third chance to redeem themselves, but if a defendant commits 3 crimes, there is a greater chance they are less likely to reconsider their actions.\n",
    "\n",
    "The AUC score slightly worsened after we tried our own model, but we can see from the false positive and false negative rates that the degree of algorithmic fairness has IMPROVED! Generally, both Blacks and Whites have their rates become closer to each other now. The false positive rate, which defines how often a defendant is mis-labeled as guilty to re-commit a crime, has become lower for Blacks and higher for Whites, making the two groups more equal to each other (although there is still a greater than 0.1 difference). There are also slightly more Whites being identified as positive than before. Unfortunately, the false negative rate has also increased for Blacks, which means that more Black defendants are not being \"caught\" correctly.  There are still many Whites, around the same amount as the prior model, that are also not being \"caught\"' correctly (which may potentially be due to their race or other features). Our model has increased the amount of defendants who are getting away with being identified for future crime. \n",
    "\n",
    "In summary, the two racial groups are now showing more similar false positive, false negative, and positive rates, but it's at the expense of a lower AUC score as well as a higher false negative rate for both groups, which means that more defendants are getting away with being identified for future crime. This is a trade-off in my model, and it points to the general idea that most models have trade-offs between algorithmic fairness and performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 5 (answered).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
