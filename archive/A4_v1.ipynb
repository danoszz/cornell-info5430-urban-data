{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663096f2",
   "metadata": {
    "id": "bizarre-tonight"
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9504f941",
   "metadata": {
    "id": "bizarre-tonight"
   },
   "source": [
    "Isaiah D. Murray (idm22@cornell.edu)\n",
    "\n",
    "Daan van der Zwagg (dv239@cornell.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3546dac",
   "metadata": {
    "id": "patent-china"
   },
   "source": [
    "#### In this assignment, we will conclude our analysis of whether the stop and frisk policy was racially discriminatory, but from a very different angle than our previous mapping analysis. We will rely heavily on logistic regression and regularized regression, as discussed in class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d7a1f",
   "metadata": {
    "id": "lPy-JHVGfPsF"
   },
   "source": [
    "# Data processing (5 points)\n",
    "\n",
    "First we need to do some data processing for consistency with previous of analysis of stop_and_frisk data. Load in the data \"sqf_sample\" and filter for stops between 2008 and 2012 (including both 2008 and 2012 in your sample). Filter for stops of white, Black, and Hispanic pedestrians using the suspect_race column. (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61cf7c9b",
   "metadata": {
    "id": "Kd54AVi-gUOq"
   },
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bb4952",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sqf_sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6308c217b554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read in csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msqf_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sqf_sample.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sqf_sample.csv'"
     ]
    }
   ],
   "source": [
    "# read in csv\n",
    "sqf_sample = pd.read_csv(\"sqf_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c310f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sqf_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaca09db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408615, 89)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a7da8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'date', 'time', 'precinct', 'xcoord', 'ycoord', 'serial',\n",
      "       'radio_run', 'inside_outside', 'location_housing', 'observation_period',\n",
      "       'suspected_crime', 'stop_length', 'identification', 'reason_explained',\n",
      "       'others_stopped', 'arrested', 'arrested_reason', 'summons_issued',\n",
      "       'officer_uniform', 'officer_verbal', 'officer_shield', 'frisked',\n",
      "       'searched', 'extra_reports', 'force_hands', 'force_wall',\n",
      "       'force_ground', 'force_drawn', 'force_pointed', 'force_baton',\n",
      "       'force_handcuffs', 'force_pepper', 'force_other', 'stopped_bc_object',\n",
      "       'stopped_bc_desc', 'stopped_bc_casing', 'stopped_bc_lookout',\n",
      "       'stopped_bc_clothing', 'stopped_bc_drugs', 'stopped_bc_furtive',\n",
      "       'stopped_bc_violent', 'stopped_bc_bulge', 'stopped_bc_other',\n",
      "       'frisked_bc_suspected_crime', 'frisked_bc_weapons', 'frisked_bc_attire',\n",
      "       'frisked_bc_actual_crime', 'frisked_bc_noncompliance',\n",
      "       'frisked_bc_threats', 'frisked_bc_prior', 'frisked_bc_furtive',\n",
      "       'frisked_bc_bulge', 'additional_report', 'additional_investigation',\n",
      "       'additional_proximity', 'additional_evasive', 'additional_associating',\n",
      "       'additional_direction', 'additional_highcrime', 'additional_time',\n",
      "       'additional_sights', 'additional_other', 'searched_hardobject',\n",
      "       'searched_outline', 'searched_admission', 'searched_other',\n",
      "       'found_contraband', 'found_pistol', 'found_rifle', 'found_assault',\n",
      "       'found_knife', 'found_machinegun', 'found_other', 'suspect_sex',\n",
      "       'suspect_race', 'suspect_hispanic', 'suspect_age', 'suspect_dob',\n",
      "       'suspect_height', 'suspect_weight', 'suspect_hair', 'suspect_eye',\n",
      "       'suspect_build', 'found_gun', 'found_weapon', 'id', 'lat', 'lon'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check columns\n",
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669dde03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>precinct</th>\n",
       "      <th>xcoord</th>\n",
       "      <th>ycoord</th>\n",
       "      <th>serial</th>\n",
       "      <th>radio_run</th>\n",
       "      <th>inside_outside</th>\n",
       "      <th>location_housing</th>\n",
       "      <th>...</th>\n",
       "      <th>suspect_height</th>\n",
       "      <th>suspect_weight</th>\n",
       "      <th>suspect_hair</th>\n",
       "      <th>suspect_eye</th>\n",
       "      <th>suspect_build</th>\n",
       "      <th>found_gun</th>\n",
       "      <th>found_weapon</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>13:01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>990071.0</td>\n",
       "      <td>204546.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neither</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>185.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1603997</td>\n",
       "      <td>40.728106</td>\n",
       "      <td>-73.978998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>22:11</td>\n",
       "      <td>77.0</td>\n",
       "      <td>996834.0</td>\n",
       "      <td>184061.0</td>\n",
       "      <td>6369.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neither</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>175.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2422905</td>\n",
       "      <td>40.671873</td>\n",
       "      <td>-73.954636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>2007-05-18</td>\n",
       "      <td>23:28</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1002197.0</td>\n",
       "      <td>182674.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>neither</td>\n",
       "      <td>...</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>705704</td>\n",
       "      <td>40.668056</td>\n",
       "      <td>-73.935306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-01-20</td>\n",
       "      <td>19:20</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1010719.0</td>\n",
       "      <td>186857.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>transit</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>180.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>heavy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2133381</td>\n",
       "      <td>40.679516</td>\n",
       "      <td>-73.904570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>19:50</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1014014.0</td>\n",
       "      <td>249325.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neither</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3425345</td>\n",
       "      <td>40.850964</td>\n",
       "      <td>-73.892414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        date   time  precinct     xcoord    ycoord  serial  radio_run  \\\n",
       "0  2009  2009-02-13  13:01       9.0   990071.0  204546.0   730.0      False   \n",
       "1  2010  2010-07-02  22:11      77.0   996834.0  184061.0  6369.0      False   \n",
       "2  2007  2007-05-18  23:28      71.0  1002197.0  182674.0  2053.0      False   \n",
       "3  2010  2010-01-20  19:20      73.0  1010719.0  186857.0   967.0      False   \n",
       "4  2012  2012-01-18  19:50      48.0  1014014.0  249325.0   334.0      False   \n",
       "\n",
       "   inside_outside location_housing  ...  suspect_height suspect_weight  \\\n",
       "0           False          neither  ...        6.166667          185.0   \n",
       "1           False          neither  ...        5.666667          175.0   \n",
       "2            True          neither  ...        5.750000          175.0   \n",
       "3            True          transit  ...        5.666667          180.0   \n",
       "4           False          neither  ...        6.000000          175.0   \n",
       "\n",
       "   suspect_hair suspect_eye  suspect_build  found_gun  found_weapon       id  \\\n",
       "0         black       brown         medium      False         False  1603997   \n",
       "1         black       brown         medium      False         False  2422905   \n",
       "2         black       brown         medium      False         False   705704   \n",
       "3         black       brown          heavy      False         False  2133381   \n",
       "4         black       brown         medium      False         False  3425345   \n",
       "\n",
       "         lat        lon  \n",
       "0  40.728106 -73.978998  \n",
       "1  40.671873 -73.954636  \n",
       "2  40.668056 -73.935306  \n",
       "3  40.679516 -73.904570  \n",
       "4  40.850964 -73.892414  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f142f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for year\n",
    "data = data[data[\"year\"]>=2008]\n",
    "data = data[data[\"year\"]<=2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1efee8fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293278, 89)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the data shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ad5dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2009 2010 2012 2008 2011]\n"
     ]
    }
   ],
   "source": [
    "# making sure that there are in fact only years 2008 to 2012\n",
    "print (data[\"year\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21fe2cca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black' 'hispanic' 'asian' 'white' nan 'other' 'native american']\n"
     ]
    }
   ],
   "source": [
    "# seeing the unique values in suspect_race\n",
    "print (data[\"suspect_race\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e53be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for race\n",
    "selected = ['black', 'hispanic', 'white']\n",
    "data = data[data[\"suspect_race\"].isin(selected)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "118ea3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black' 'hispanic' 'white']\n"
     ]
    }
   ],
   "source": [
    "# seeing the unique values in suspect_race\n",
    "print (data[\"suspect_race\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689c4a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273235, 89)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ee4eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>precinct</th>\n",
       "      <th>xcoord</th>\n",
       "      <th>ycoord</th>\n",
       "      <th>serial</th>\n",
       "      <th>radio_run</th>\n",
       "      <th>inside_outside</th>\n",
       "      <th>location_housing</th>\n",
       "      <th>...</th>\n",
       "      <th>suspect_height</th>\n",
       "      <th>suspect_weight</th>\n",
       "      <th>suspect_hair</th>\n",
       "      <th>suspect_eye</th>\n",
       "      <th>suspect_build</th>\n",
       "      <th>found_gun</th>\n",
       "      <th>found_weapon</th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>13:01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>990071.0</td>\n",
       "      <td>204546.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neither</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>185.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1603997</td>\n",
       "      <td>40.728106</td>\n",
       "      <td>-73.978998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>22:11</td>\n",
       "      <td>77.0</td>\n",
       "      <td>996834.0</td>\n",
       "      <td>184061.0</td>\n",
       "      <td>6369.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neither</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>175.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2422905</td>\n",
       "      <td>40.671873</td>\n",
       "      <td>-73.954636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-01-20</td>\n",
       "      <td>19:20</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1010719.0</td>\n",
       "      <td>186857.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>transit</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>180.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>heavy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2133381</td>\n",
       "      <td>40.679516</td>\n",
       "      <td>-73.904570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>19:50</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1014014.0</td>\n",
       "      <td>249325.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neither</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3425345</td>\n",
       "      <td>40.850964</td>\n",
       "      <td>-73.892414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010-11-22</td>\n",
       "      <td>22:35</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1008499.0</td>\n",
       "      <td>191844.0</td>\n",
       "      <td>8631.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neither</td>\n",
       "      <td>...</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>black</td>\n",
       "      <td>brown</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2650242</td>\n",
       "      <td>40.693211</td>\n",
       "      <td>-73.912556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        date   time  precinct     xcoord    ycoord  serial  radio_run  \\\n",
       "0  2009  2009-02-13  13:01       9.0   990071.0  204546.0   730.0      False   \n",
       "1  2010  2010-07-02  22:11      77.0   996834.0  184061.0  6369.0      False   \n",
       "3  2010  2010-01-20  19:20      73.0  1010719.0  186857.0   967.0      False   \n",
       "4  2012  2012-01-18  19:50      48.0  1014014.0  249325.0   334.0      False   \n",
       "5  2010  2010-11-22  22:35      83.0  1008499.0  191844.0  8631.0      False   \n",
       "\n",
       "   inside_outside location_housing  ...  suspect_height suspect_weight  \\\n",
       "0           False          neither  ...        6.166667          185.0   \n",
       "1           False          neither  ...        5.666667          175.0   \n",
       "3            True          transit  ...        5.666667          180.0   \n",
       "4           False          neither  ...        6.000000          175.0   \n",
       "5           False          neither  ...        5.750000          170.0   \n",
       "\n",
       "   suspect_hair suspect_eye  suspect_build  found_gun  found_weapon       id  \\\n",
       "0         black       brown         medium      False         False  1603997   \n",
       "1         black       brown         medium      False         False  2422905   \n",
       "3         black       brown          heavy      False         False  2133381   \n",
       "4         black       brown         medium      False         False  3425345   \n",
       "5         black       brown         medium      False         False  2650242   \n",
       "\n",
       "         lat        lon  \n",
       "0  40.728106 -73.978998  \n",
       "1  40.671873 -73.954636  \n",
       "3  40.679516 -73.904570  \n",
       "4  40.850964 -73.892414  \n",
       "5  40.693211 -73.912556  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021bad6",
   "metadata": {
    "id": "ranging-edition"
   },
   "source": [
    "## Using regression to analyze the frisk decision. (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f60db",
   "metadata": {
    "id": "canadian-signature"
   },
   "source": [
    "We will start by testing for racial discrimination in the decision to conduct a frisk after a stop: ie, whether Black and Hispanic pedestrians are more likely to be frisked (patted down for weapons) after they are stopped, controlling for other factors.\n",
    "\n",
    "a. Using statsmodels, perform a logistic regression, using `frisked` as the dependent variable and `suspect_race` as the independent variable, to assess how the probability of being frisked after a stop varies by race. Write a few sentences interpreting the results, making sure to answer the following questions: which value of suspect_race is omitted from the regression coefficients? Which race groups are most likely to be frisked after being stopped? How do you interpret the magnitude and sign of the coefficients? How do you interpret their statistical significance and confidence intervals? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d9c5c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "408610    False\n",
      "408611    False\n",
      "408612    False\n",
      "408613     True\n",
      "408614    False\n",
      "Name: frisked_bc_weapons, Length: 408615, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#preview the data\n",
    "print (data['frisked_bc_weapons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79ab91a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        False  True \n",
      "0           1      0\n",
      "1           1      0\n",
      "2           1      0\n",
      "3           1      0\n",
      "4           1      0\n",
      "...       ...    ...\n",
      "408610      1      0\n",
      "408611      1      0\n",
      "408612      1      0\n",
      "408613      0      1\n",
      "408614      1      0\n",
      "\n",
      "[408615 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# converting data to dummies\n",
    "# edit d: \n",
    "dummies = pd.get_dummies(data['frisked_bc_weapons'])\n",
    "print (dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "311be611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'frisked_bc_weapons_dummies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'frisked_bc_weapons_dummies'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-fcb9d4c43dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# previewing the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frisked_bc_weapons_dummies'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 0 = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 1 = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'frisked_bc_weapons_dummies'"
     ]
    }
   ],
   "source": [
    "# previewing the data\n",
    "print (data['frisked_bc_weapons_dummies'].unique())\n",
    "# 0 = False\n",
    "# 1 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd202e43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'frisked_bc_weapons_dummies' is not defined\n    frisked_bc_weapons_dummies ~ C(suspect_race)\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         return eval(code, {}, VarLookupDict([inner_namespace]\n\u001b[0m\u001b[1;32m    166\u001b[0m                                             + self._namespaces))\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frisked_bc_weapons_dummies' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPatsyError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1d8bac63ab6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'frisked_bc_weapons_dummies ~ C(suspect_race)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogitfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogitfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[0m\u001b[1;32m    170\u001b[0m                                   missing=missing)\n\u001b[1;32m    171\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/formula/formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[0m\u001b[1;32m     64\u001b[0m                                NA_action=na_action)\n\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \"\"\"\n\u001b[1;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0m\u001b[1;32m    310\u001b[0m                                       NA_action, return_type)\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0m\u001b[1;32m    165\u001b[0m                                       NA_action)\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelDesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         return design_matrix_builders([formula_like.lhs_termlist,\n\u001b[0m\u001b[1;32m     67\u001b[0m                                        formula_like.rhs_termlist],\n\u001b[1;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;31m# on some data to find out what type of data they return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     (num_column_counts,\n\u001b[0;32m--> 693\u001b[0;31m      \u001b[0mcat_levels_contrasts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_examine_factor_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_factors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m                                                    \u001b[0mfactor_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                                                    \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/build.py\u001b[0m in \u001b[0;36m_examine_factor_types\u001b[0;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamine_needed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mguess_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, memorize_state, data)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         return self._eval(memorize_state[\"eval_code\"],\n\u001b[0m\u001b[1;32m    565\u001b[0m                           \u001b[0mmemorize_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                           data)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36m_eval\u001b[0;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0minner_namespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVarLookupDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transforms\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         return call_and_wrap_exc(\"Error evaluating factor\",\n\u001b[0m\u001b[1;32m    548\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                                  \u001b[0mmemorize_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_env\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                  origin)\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raise new_exc from e\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# In python 2, we just let the original exception escape -- better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'frisked_bc_weapons_dummies' is not defined\n    frisked_bc_weapons_dummies ~ C(suspect_race)\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "f = 'frisked_bc_weapons_dummies ~ C(suspect_race)'\n",
    "logitfit = smf.logit(formula = str(f), data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51495",
   "metadata": {
    "id": "earned-mainstream"
   },
   "source": [
    "b. Now perform a linear regression instead of a logistic regression using the same formula. How is the interpretation of the coefficients similar or different in the two regressions? What are the advantages of each? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "027a2039",
   "metadata": {
    "id": "1lTNBfBqgXMW"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-b0db8a4b36a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#logistic regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'frisked_bc_weapons_dummies ~ C(suspect_race)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlin_regress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"frisked_bc_weapons_dummies\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"suspect_race\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlin_regress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    870\u001b[0m     def __init__(self, endog, exog=None, missing='none', hasconst=None,\n\u001b[0;32m    871\u001b[0m                  **kwargs):\n\u001b[1;32m--> 872\u001b[1;33m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    873\u001b[0m                                   hasconst=hasconst, **kwargs)\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    704\u001b[0m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0;32m    705\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'missing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[0;32m     78\u001b[0m                                       **kwargs)\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[0;32m    673\u001b[0m                  **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mcheck_implicit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mexog_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mMissingDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exog contains inf or nans'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mexog_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "f = 'frisked_bc_weapons_dummies ~ C(suspect_race)'\n",
    "lin_regress = sm.OLS(np.array(data[\"frisked_bc_weapons_dummies\"]), np.array(data[\"suspect_race\"])).fit()\n",
    "\n",
    "print (lin_regress.summary())\n",
    "\n",
    "#lin_reg=sm.OLS(ytrain,xtrain).fit()\n",
    "#print(lin_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e9500",
   "metadata": {
    "id": "rgk3tioqWpJg"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d96904ae",
   "metadata": {
    "id": "constitutional-place"
   },
   "source": [
    "c. The regression using only race as an independent variable is a good starting point, but it does not control for any other variables. What other variables do you think are important to control for, and why?  (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaeb7be",
   "metadata": {
    "id": "pS3NmINSWsDL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050e0162",
   "metadata": {
    "id": "assumed-employment"
   },
   "source": [
    "d. Run a logistic regression where you control for both race and for the \"precinct\" variable, which encodes the police precinct in which the stop occurred. Make sure to control for precinct as a categorical, not a numerical, variable, by writing it as C(precinct) in the regression formula - why is this important to do?\n",
    "\n",
    "How do the race coefficients change, and what does that mean? How does the interpretation of this regression differ from the regression in which you only control for race? Make one argument in favor of reporting results controlling for location, and one argument against it. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f3c3381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.148051\n",
      "         Iterations 9\n",
      "                               Logit Regression Results                               \n",
      "======================================================================================\n",
      "Dep. Variable:     frisked_bc_weapons_dummies   No. Observations:               273235\n",
      "Model:                                  Logit   Df Residuals:                   273157\n",
      "Method:                                   MLE   Df Model:                           77\n",
      "Date:                        Thu, 04 Nov 2021   Pseudo R-squ.:                 0.01736\n",
      "Time:                                16:12:30   Log-Likelihood:                -40453.\n",
      "converged:                               True   LL-Null:                       -41167.\n",
      "Covariance Type:                    nonrobust   LLR p-value:                6.634e-248\n",
      "===============================================================================================\n",
      "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                      -3.4831      0.161    -21.658      0.000      -3.798      -3.168\n",
      "C(suspect_race)[T.hispanic]    -0.0594      0.026     -2.286      0.022      -0.110      -0.008\n",
      "C(suspect_race)[T.white]        0.0560      0.042      1.319      0.187      -0.027       0.139\n",
      "C(precinct)[T.5.0]              0.5918      0.206      2.870      0.004       0.188       0.996\n",
      "C(precinct)[T.6.0]              0.1364      0.214      0.638      0.523      -0.283       0.555\n",
      "C(precinct)[T.7.0]              0.3535      0.201      1.756      0.079      -0.041       0.748\n",
      "C(precinct)[T.9.0]              0.6081      0.185      3.292      0.001       0.246       0.970\n",
      "C(precinct)[T.10.0]             0.5696      0.200      2.847      0.004       0.177       0.962\n",
      "C(precinct)[T.13.0]             0.7839      0.184      4.263      0.000       0.423       1.144\n",
      "C(precinct)[T.14.0]             0.4070      0.175      2.324      0.020       0.064       0.750\n",
      "C(precinct)[T.17.0]             0.5410      0.230      2.355      0.019       0.091       0.991\n",
      "C(precinct)[T.18.0]             0.3458      0.206      1.675      0.094      -0.059       0.750\n",
      "C(precinct)[T.19.0]             0.5536      0.189      2.924      0.003       0.182       0.925\n",
      "C(precinct)[T.20.0]            -0.0672      0.216     -0.311      0.756      -0.491       0.357\n",
      "C(precinct)[T.22.0]             0.1638      0.316      0.518      0.604      -0.455       0.783\n",
      "C(precinct)[T.23.0]             0.5688      0.169      3.357      0.001       0.237       0.901\n",
      "C(precinct)[T.24.0]             0.5920      0.190      3.110      0.002       0.219       0.965\n",
      "C(precinct)[T.25.0]             0.9940      0.171      5.812      0.000       0.659       1.329\n",
      "C(precinct)[T.26.0]             0.4856      0.190      2.556      0.011       0.113       0.858\n",
      "C(precinct)[T.28.0]             0.3737      0.181      2.068      0.039       0.020       0.728\n",
      "C(precinct)[T.30.0]             0.1456      0.193      0.755      0.450      -0.232       0.524\n",
      "C(precinct)[T.32.0]             0.5860      0.171      3.419      0.001       0.250       0.922\n",
      "C(precinct)[T.33.0]             0.1212      0.197      0.616      0.538      -0.264       0.507\n",
      "C(precinct)[T.34.0]             0.0483      0.187      0.258      0.796      -0.318       0.414\n",
      "C(precinct)[T.40.0]             0.3137      0.171      1.833      0.067      -0.022       0.649\n",
      "C(precinct)[T.41.0]             0.1386      0.184      0.754      0.451      -0.222       0.499\n",
      "C(precinct)[T.42.0]             0.6553      0.173      3.792      0.000       0.317       0.994\n",
      "C(precinct)[T.43.0]             0.8441      0.169      4.981      0.000       0.512       1.176\n",
      "C(precinct)[T.44.0]             0.4357      0.172      2.532      0.011       0.098       0.773\n",
      "C(precinct)[T.45.0]             0.2005      0.201      1.000      0.317      -0.192       0.594\n",
      "C(precinct)[T.46.0]            -0.1408      0.186     -0.757      0.449      -0.506       0.224\n",
      "C(precinct)[T.47.0]             0.6131      0.175      3.501      0.000       0.270       0.956\n",
      "C(precinct)[T.48.0]             0.1843      0.203      0.909      0.363      -0.213       0.581\n",
      "C(precinct)[T.49.0]            -0.3086      0.201     -1.535      0.125      -0.703       0.085\n",
      "C(precinct)[T.50.0]             0.2464      0.226      1.089      0.276      -0.197       0.690\n",
      "C(precinct)[T.52.0]             0.7235      0.173      4.184      0.000       0.385       1.062\n",
      "C(precinct)[T.60.0]            -0.0551      0.186     -0.296      0.767      -0.420       0.310\n",
      "C(precinct)[T.61.0]            -0.4223      0.209     -2.023      0.043      -0.832      -0.013\n",
      "C(precinct)[T.62.0]            -0.7181      0.237     -3.034      0.002      -1.182      -0.254\n",
      "C(precinct)[T.63.0]             0.3537      0.205      1.724      0.085      -0.048       0.756\n",
      "C(precinct)[T.66.0]             0.6278      0.197      3.187      0.001       0.242       1.014\n",
      "C(precinct)[T.67.0]             0.3497      0.175      1.999      0.046       0.007       0.693\n",
      "C(precinct)[T.68.0]             0.2006      0.219      0.917      0.359      -0.228       0.629\n",
      "C(precinct)[T.69.0]            -0.1579      0.199     -0.794      0.427      -0.548       0.232\n",
      "C(precinct)[T.70.0]             0.0153      0.180      0.085      0.932      -0.338       0.368\n",
      "C(precinct)[T.71.0]            -0.7155      0.221     -3.235      0.001      -1.149      -0.282\n",
      "C(precinct)[T.72.0]            -0.0929      0.208     -0.446      0.656      -0.501       0.315\n",
      "C(precinct)[T.73.0]             0.0221      0.170      0.130      0.897      -0.311       0.355\n",
      "C(precinct)[T.75.0]            -0.0506      0.169     -0.299      0.765      -0.382       0.280\n",
      "C(precinct)[T.76.0]            -0.4767      0.221     -2.155      0.031      -0.910      -0.043\n",
      "C(precinct)[T.77.0]             0.1140      0.179      0.635      0.525      -0.238       0.466\n",
      "C(precinct)[T.78.0]            -0.1456      0.239     -0.610      0.542      -0.613       0.322\n",
      "C(precinct)[T.79.0]             0.0665      0.173      0.385      0.701      -0.272       0.405\n",
      "C(precinct)[T.81.0]            -0.2479      0.185     -1.337      0.181      -0.611       0.115\n",
      "C(precinct)[T.83.0]            -0.3084      0.187     -1.647      0.100      -0.675       0.059\n",
      "C(precinct)[T.84.0]             0.4511      0.194      2.324      0.020       0.071       0.832\n",
      "C(precinct)[T.88.0]             0.2293      0.186      1.233      0.218      -0.135       0.594\n",
      "C(precinct)[T.90.0]            -0.1448      0.181     -0.799      0.424      -0.500       0.210\n",
      "C(precinct)[T.94.0]             0.0698      0.246      0.284      0.776      -0.412       0.551\n",
      "C(precinct)[T.100.0]            0.0609      0.208      0.293      0.770      -0.347       0.469\n",
      "C(precinct)[T.101.0]            0.3246      0.177      1.834      0.067      -0.022       0.671\n",
      "C(precinct)[T.102.0]            0.1473      0.191      0.770      0.441      -0.227       0.522\n",
      "C(precinct)[T.103.0]            0.3799      0.172      2.205      0.027       0.042       0.717\n",
      "C(precinct)[T.104.0]           -0.8514      0.225     -3.783      0.000      -1.293      -0.410\n",
      "C(precinct)[T.105.0]           -0.0784      0.189     -0.414      0.679      -0.449       0.292\n",
      "C(precinct)[T.106.0]           -0.1274      0.208     -0.613      0.540      -0.535       0.280\n",
      "C(precinct)[T.107.0]           -0.3712      0.216     -1.719      0.086      -0.794       0.052\n",
      "C(precinct)[T.108.0]           -0.5924      0.225     -2.631      0.009      -1.034      -0.151\n",
      "C(precinct)[T.109.0]           -0.6485      0.206     -3.154      0.002      -1.051      -0.246\n",
      "C(precinct)[T.110.0]           -0.2025      0.186     -1.087      0.277      -0.568       0.163\n",
      "C(precinct)[T.111.0]           -0.3936      0.235     -1.676      0.094      -0.854       0.067\n",
      "C(precinct)[T.112.0]           -0.5352      0.262     -2.046      0.041      -1.048      -0.023\n",
      "C(precinct)[T.113.0]            0.0737      0.181      0.407      0.684      -0.281       0.428\n",
      "C(precinct)[T.114.0]           -0.2201      0.187     -1.176      0.240      -0.587       0.147\n",
      "C(precinct)[T.115.0]            0.1273      0.177      0.718      0.472      -0.220       0.475\n",
      "C(precinct)[T.120.0]           -0.2008      0.176     -1.143      0.253      -0.545       0.143\n",
      "C(precinct)[T.122.0]           -1.3217      0.242     -5.452      0.000      -1.797      -0.847\n",
      "C(precinct)[T.123.0]           -0.7442      0.288     -2.583      0.010      -1.309      -0.180\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "f = 'frisked_bc_weapons_dummies ~ C(suspect_race) + C(precinct)'\n",
    "\n",
    "logitfit = smf.logit(formula = str(f), data = data).fit()\n",
    "print(logitfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534b2bb",
   "metadata": {
    "id": "dI-I4F9jgYqr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90b8077e",
   "metadata": {
    "id": "xddOFV6kWvzy"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef100df3",
   "metadata": {
    "id": "expected-whole"
   },
   "source": [
    "e. In a few sentences, explain why it is a BAD idea, conceptually, to control for the following variables if we are trying to assess whether the police racially discriminate in whom they frisk after a stop: a) \"found.weapon\", which encodes whether the frisk found a weapon, and b) \"suspect.eye\" and \"suspect.hair\", which encode the suspect's eye and hair color. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e73c5",
   "metadata": {
    "id": "_5dWS0LAW6De"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0241c72a",
   "metadata": {
    "id": "closed-difference"
   },
   "source": [
    "f. In a few sentences, explain the problem of omitted variable bias in this analysis, and how it would undermine the conclusions. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ac2df",
   "metadata": {
    "id": "74cAqUPgW7Mu"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e62d6fbc",
   "metadata": {
    "id": "mBwIUjuRt5o2"
   },
   "source": [
    "g. In a few sentences, explain why only examining whether someone is frisked after a stop might fail to provide a full picture of discrimination in the stop and frisk policy. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec60f99",
   "metadata": {
    "id": "IuBEAzCVW7zQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e846ed88",
   "metadata": {
    "id": "grateful-chassis"
   },
   "source": [
    "## Outcome analysis using regularized regression (65 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19c770",
   "metadata": {
    "id": "scientific-franchise"
   },
   "source": [
    "Because of the issues with omitted variables in analyses like the one above, *outcome* tests are often used: these look not at the rate at which a decision is made (like the decision to frisk), but at the outcome of the decision (for example, if the frisk is conducted to find a weapon, does it actually find one?) Now we will use an outcome-style analysis. Specifically, we will fit a machine learning model to predict the probability that each stop which was conducted on suspicion the pedestrian possessed a weapon actually finds a weapon. Stops which are very unlikely to find a weapon arguably violate the Fourth Amendment, which prohibits unreasonable searches; if such stops disproportionately occur of certain race groups, the policy may violate the Fourteenth Amendment, which prohibits racial discrimination. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ebb84",
   "metadata": {
    "id": "-CaMrTP0NlPY"
   },
   "source": [
    "a. In this portion of this analysis, you will be using a smaller version of the data to speed up model fitting. Load in \"small_sqf_sample\". As before, we need to do some data processing for consistency with previous of analysis of this data. Load in the data and filter for stops between 2008 and 2012 (including both 2008 and 2012); filter for stops of white, Black, and Hispanic pedestrians using the suspect_race column; and filter for stops conducted on suspicion of criminal posession of a weapon (ie, suspected_crime == 'cpw'). (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afb6baef",
   "metadata": {
    "id": "cDZV0_2ygaOM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204308, 89)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "sample_data = pd.read_csv(\"small_sqf_sample.csv\")\n",
    "\n",
    "# check: size\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43873b4b",
   "metadata": {
    "id": "cDZV0_2ygaOM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010 2012 2011 2008 2009]\n",
      "['black' 'white' 'hispanic']\n",
      "['cpw']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36271, 89)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering for year between 2008 and 2012, renaming \"sample_data\" to \"sample_data_filtered\" \n",
    "sample_data_filtered = sample_data.loc[(sample_data[\"year\"] >= 2008) & (sample_data[\"year\"]<=2012)]\n",
    "\n",
    "# check: print unique values in \"year\" columm\n",
    "print(sample_data_filtered[\"year\"].unique())\n",
    "\n",
    "# filtering for race\n",
    "selected_race = ['black', 'hispanic', 'white']\n",
    "sample_data_filtered = sample_data_filtered[sample_data_filtered[\"suspect_race\"].isin(selected_race)]\n",
    "\n",
    "# check: print unique values in \"suspect_race\" column\n",
    "print (sample_data_filtered[\"suspect_race\"].unique())\n",
    "\n",
    "# filtering for suspected crime\n",
    "sample_data_filtered = sample_data_filtered[sample_data_filtered[\"suspected_crime\"]==\"cpw\"]\n",
    "\n",
    "# check: print unique values in \"suspected_crime\" column\n",
    "print (sample_data_filtered[\"suspected_crime\"].unique())\n",
    "\n",
    "# check: print size\n",
    "sample_data_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f8da3",
   "metadata": {
    "id": "confident-array"
   },
   "source": [
    "\n",
    "b. We will be fitting the regression model \n",
    "\n",
    "`found_weapon ~ C(precinct) * C(suspect_race) + C(location_housing) + C(year) + suspect_age + suspect_height + suspect_weight + suspect_sex + ADDITIONAL_CIRCUMSTANCE_COLUMNS` \n",
    "\n",
    "where ADDITIONAL_CIRCUMSTANCE_COLUMNS are any columns that begin with \"stopped_bc\" or \"additional_\" besides \"additional_other\" and \"stopped_bc_other\". You can get these columns by running\n",
    "\n",
    "`ADDITIONAL_CIRCUMSTANCE_COLUMNS = [a for a in d.columns if ('stopped_bc' in a or 'additional_' in a) and a not in (['additional_other', 'stopped_bc_other'])]`\n",
    "\n",
    "You should have 18 additional columns. These columns provide more information about the circumstances of the stop, and we include them for consistency with the original analysis and because they turn out to be important for predictive performance. \n",
    "\n",
    "Drop any rows with missing values in any of the variables you need. \n",
    "\n",
    "Now, we need to put the data into a format which sklearn can use later - ie, numpy arrays. Do this with \"patsy\" library and the \"dmatrix\" function. You can call dmatrix as follows:\n",
    "\n",
    "`sqf_X = patsy.dmatrix('C(precinct) * C(suspect_race) + C(location_housing) + C(year) + suspect_age + suspect_height + suspect_weight + suspect_sex +' + '+'.join(ADDITIONAL_CIRCUMSTANCE_COLUMNS),sqf_data, return_type='dataframe')`\n",
    "\n",
    "and it will return a dataframe on which you can fit a regression model. The first argument to dmatrix is the formula that you want to use to make the dataframe; the second argument gives patsy the data you want to use; return_type='dataframe' ensures that you get a dataframe, not a patsy object which is hard to use.\n",
    "\n",
    "Look at the output of dmatrix and explain what the columns mean. Why can't we just pass the columns from the original dataframe directly into the sklearn function? (8 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6a14a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# create the additional columns (line breaks used for readibility)\n",
    "ADDITIONAL_CIRCUMSTANCE_COLUMNS = [a for a in sample_data_filtered.columns \n",
    "                                   if ('stopped_bc' in a or 'additional_' in a) \n",
    "                                   and a not in (['additional_other', 'stopped_bc_other'])]\n",
    "\n",
    "# check: length of additional columns → 18\n",
    "print(len(ADDITIONAL_CIRCUMSTANCE_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49d846d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['found_weapon', 'precinct', 'suspect_race', 'location_housing', 'year', 'suspect_age', 'suspect_height', 'suspect_weight', 'suspect_sex', 'stopped_bc_object', 'stopped_bc_desc', 'stopped_bc_casing', 'stopped_bc_lookout', 'stopped_bc_clothing', 'stopped_bc_drugs', 'stopped_bc_furtive', 'stopped_bc_violent', 'stopped_bc_bulge', 'additional_report', 'additional_investigation', 'additional_proximity', 'additional_evasive', 'additional_associating', 'additional_direction', 'additional_highcrime', 'additional_time', 'additional_sights']\n"
     ]
    }
   ],
   "source": [
    "# set columns for model fitting; variables mentioned in regression model + additional cirumstances columns\n",
    "model_columns = [\"found_weapon\", \"precinct\", \"suspect_race\", \"location_housing\", \n",
    "                 \"year\", \"suspect_age\", \"suspect_height\", \"suspect_weight\", \"suspect_sex\"]\n",
    "\n",
    "model_columns = model_columns + ADDITIONAL_CIRCUMSTANCE_COLUMNS;\n",
    "\n",
    "# check: print column names\n",
    "print(model_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8cc08cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# check: print amount columns\n",
    "print(len(model_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "722ee409",
   "metadata": {
    "id": "n42o63nLgdET",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>found_weapon</th>\n",
       "      <th>precinct</th>\n",
       "      <th>suspect_race</th>\n",
       "      <th>location_housing</th>\n",
       "      <th>year</th>\n",
       "      <th>suspect_age</th>\n",
       "      <th>suspect_height</th>\n",
       "      <th>suspect_weight</th>\n",
       "      <th>suspect_sex</th>\n",
       "      <th>...</th>\n",
       "      <th>stopped_bc_bulge</th>\n",
       "      <th>additional_report</th>\n",
       "      <th>additional_investigation</th>\n",
       "      <th>additional_proximity</th>\n",
       "      <th>additional_evasive</th>\n",
       "      <th>additional_associating</th>\n",
       "      <th>additional_direction</th>\n",
       "      <th>additional_highcrime</th>\n",
       "      <th>additional_time</th>\n",
       "      <th>additional_sights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.0</td>\n",
       "      <td>black</td>\n",
       "      <td>neither</td>\n",
       "      <td>2010</td>\n",
       "      <td>49</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>26.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>housing</td>\n",
       "      <td>2008</td>\n",
       "      <td>35</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>130.0</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>79.0</td>\n",
       "      <td>black</td>\n",
       "      <td>housing</td>\n",
       "      <td>2009</td>\n",
       "      <td>30</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>180.0</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "      <td>black</td>\n",
       "      <td>neither</td>\n",
       "      <td>2011</td>\n",
       "      <td>31</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>270.0</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>housing</td>\n",
       "      <td>2010</td>\n",
       "      <td>16</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>160.0</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  found_weapon  precinct suspect_race location_housing  year  \\\n",
       "0      0         False      41.0        black          neither  2010   \n",
       "1      7         False      26.0     hispanic          housing  2008   \n",
       "2     17         False      79.0        black          housing  2009   \n",
       "3     20         False     100.0        black          neither  2011   \n",
       "4     23         False      32.0     hispanic          housing  2010   \n",
       "\n",
       "   suspect_age  suspect_height  suspect_weight suspect_sex  ...  \\\n",
       "0           49        6.000000           170.0        male  ...   \n",
       "1           35        5.250000           130.0      female  ...   \n",
       "2           30        5.583333           180.0        male  ...   \n",
       "3           31        6.333333           270.0        male  ...   \n",
       "4           16        5.500000           160.0        male  ...   \n",
       "\n",
       "   stopped_bc_bulge  additional_report  additional_investigation  \\\n",
       "0             False              False                     False   \n",
       "1             False              False                      True   \n",
       "2              True              False                     False   \n",
       "3             False               True                     False   \n",
       "4             False              False                     False   \n",
       "\n",
       "   additional_proximity  additional_evasive  additional_associating  \\\n",
       "0                 False               False                   False   \n",
       "1                  True               False                   False   \n",
       "2                 False               False                   False   \n",
       "3                 False               False                   False   \n",
       "4                 False               False                   False   \n",
       "\n",
       "   additional_direction  additional_highcrime  additional_time  \\\n",
       "0                 False                 False            False   \n",
       "1                 False                 False            False   \n",
       "2                 False                  True             True   \n",
       "3                 False                  True             True   \n",
       "4                 False                  True            False   \n",
       "\n",
       "   additional_sights  \n",
       "0              False  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "4              False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter data with selected model columns\n",
    "sample_data_filtered = sample_data_filtered[model_columns]\n",
    "\n",
    "#reset index\n",
    "sample_data_filtered = sample_data_filtered.reset_index()\n",
    "\n",
    "#check: display filtered dataset head with specific columns needed for the model\n",
    "sample_data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "318896e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size: (36271, 28) size after drop: (36056, 28)\n"
     ]
    }
   ],
   "source": [
    "# drop missing values we need in dataset\n",
    "sample_data_dropped = sample_data_filtered.dropna()\n",
    "\n",
    "# check: compare initial size of data and after drop\n",
    "print(\"initial size:\", sample_data_filtered.shape, \"size after drop:\", sample_data_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d28666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>C(precinct)[T.5.0]</th>\n",
       "      <th>C(precinct)[T.6.0]</th>\n",
       "      <th>C(precinct)[T.7.0]</th>\n",
       "      <th>C(precinct)[T.9.0]</th>\n",
       "      <th>C(precinct)[T.10.0]</th>\n",
       "      <th>C(precinct)[T.13.0]</th>\n",
       "      <th>C(precinct)[T.14.0]</th>\n",
       "      <th>C(precinct)[T.17.0]</th>\n",
       "      <th>C(precinct)[T.18.0]</th>\n",
       "      <th>...</th>\n",
       "      <th>C(precinct)[T.112.0]:C(suspect_race)[T.white]</th>\n",
       "      <th>C(precinct)[T.113.0]:C(suspect_race)[T.white]</th>\n",
       "      <th>C(precinct)[T.114.0]:C(suspect_race)[T.white]</th>\n",
       "      <th>C(precinct)[T.115.0]:C(suspect_race)[T.white]</th>\n",
       "      <th>C(precinct)[T.120.0]:C(suspect_race)[T.white]</th>\n",
       "      <th>C(precinct)[T.122.0]:C(suspect_race)[T.white]</th>\n",
       "      <th>C(precinct)[T.123.0]:C(suspect_race)[T.white]</th>\n",
       "      <th>suspect_age</th>\n",
       "      <th>suspect_height</th>\n",
       "      <th>suspect_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  C(precinct)[T.5.0]  C(precinct)[T.6.0]  C(precinct)[T.7.0]  \\\n",
       "0        1.0                 0.0                 0.0                 0.0   \n",
       "1        1.0                 0.0                 0.0                 0.0   \n",
       "2        1.0                 0.0                 0.0                 0.0   \n",
       "3        1.0                 0.0                 0.0                 0.0   \n",
       "4        1.0                 0.0                 0.0                 0.0   \n",
       "\n",
       "   C(precinct)[T.9.0]  C(precinct)[T.10.0]  C(precinct)[T.13.0]  \\\n",
       "0                 0.0                  0.0                  0.0   \n",
       "1                 0.0                  0.0                  0.0   \n",
       "2                 0.0                  0.0                  0.0   \n",
       "3                 0.0                  0.0                  0.0   \n",
       "4                 0.0                  0.0                  0.0   \n",
       "\n",
       "   C(precinct)[T.14.0]  C(precinct)[T.17.0]  C(precinct)[T.18.0]  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  0.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   C(precinct)[T.112.0]:C(suspect_race)[T.white]  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   C(precinct)[T.113.0]:C(suspect_race)[T.white]  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   C(precinct)[T.114.0]:C(suspect_race)[T.white]  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   C(precinct)[T.115.0]:C(suspect_race)[T.white]  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   C(precinct)[T.120.0]:C(suspect_race)[T.white]  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   C(precinct)[T.122.0]:C(suspect_race)[T.white]  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   C(precinct)[T.123.0]:C(suspect_race)[T.white]  suspect_age  suspect_height  \\\n",
       "0                                            0.0         49.0        6.000000   \n",
       "1                                            0.0         35.0        5.250000   \n",
       "2                                            0.0         30.0        5.583333   \n",
       "3                                            0.0         31.0        6.333333   \n",
       "4                                            0.0         16.0        5.500000   \n",
       "\n",
       "   suspect_weight  \n",
       "0           170.0  \n",
       "1           130.0  \n",
       "2           180.0  \n",
       "3           270.0  \n",
       "4           160.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import patsy and dmatrix\n",
    "import patsy\n",
    "from patsy import dmatrices, dmatrix, demo_data\n",
    "\n",
    "# set data in format sklearn can use with patsy and \n",
    "sqf_X = patsy.dmatrix('C(precinct) * C(suspect_race) + C(location_housing) + C(year) + suspect_age + suspect_height + suspect_weight + suspect_sex +' + '+'.join(ADDITIONAL_CIRCUMSTANCE_COLUMNS), sample_data_dropped, return_type='dataframe')\n",
    "\n",
    "# check: see head dataframe converted to dmatrix\n",
    "sqf_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a085e",
   "metadata": {
    "id": "N3N-RXXKX1PQ"
   },
   "source": [
    "## Analyze: dmatrix and differences (WIP 🛶)\n",
    "\n",
    "Look at the output of dmatrix and explain what the columns mean. Why can't we just pass the columns from the original dataframe directly into the sklearn function? (8 points)\n",
    "\n",
    "* coding categorical data (TRUE/FALSE) to numerical data, by adding columns for each unique entry in a categorical column. It brings a \n",
    "\n",
    "* regression can work with numbers, not categorical features as strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e29fd",
   "metadata": {
    "id": "AAib9e-WfUdF"
   },
   "source": [
    "c. As discussed in class, when fitting machine learning models, you should always divide the dataset into a train, val, and test set. Randomly divide the filtered, processed data into three pieces - the train set (60%), the val set (20%) and the test set (20%). (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ba8b01b",
   "metadata": {
    "id": "ditQALf_geMN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 36056\n",
      "train: 21633 , train frac: 0.5999833592189927\n",
      "val: 7211 , val frac: 0.19999445307299757\n",
      "test: 7212 , test frac: 0.20002218770800975\n"
     ]
    }
   ],
   "source": [
    "# divide datasets in train, val and test sets.\n",
    "# source: https://stackoverflow.com/questions/17412439/how-to-split-data-into-trainset-and-testset-randomly\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split randomnly initial data into 60/40\n",
    "sqf_X_train, sqf_X_other = train_test_split(sqf_X, test_size=0.4)\n",
    "\n",
    "# split other data into 50/50, therefor 40 (sqf_X_other) goes 20/20\n",
    "sqf_X_val, sqf_X_test = train_test_split(sqf_X_other, test_size=0.5)\n",
    "\n",
    "# critique: above method of randomizing twice can raise questions of true randomization (probability) of a single entry ending up in a specific set\n",
    "\n",
    "# check: data lengths to verify 60/20/20\n",
    "\n",
    "print(\"total:\", len(sqf_X))\n",
    "print(\"train:\", len(sqf_X_train), \", train frac:\", len(sqf_X_train) / len(sqf_X))\n",
    "print(\"val:\", len(sqf_X_val), \", val frac:\", len(sqf_X_val) / len(sqf_X))\n",
    "print(\"test:\", len(sqf_X_test), \", test frac:\", len(sqf_X_test) / len(sqf_X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ccbba",
   "metadata": {
    "id": "MWZp2Jw7TKVm"
   },
   "source": [
    "d. We will be training a regularized logistic regression model to predict the outcome. When using many machine learning models, including regularized logistic regression, it is important to preprocess the input features so they are all on the same scale, for reasons discussed in class. In this case, we will take each column in the input data, subtract its mean, and divide by its standard deviation. This makes it so each column of the data has mean 0 and standard deviation 1. \n",
    "\n",
    "When scaling the data, it is important to compute the scaling using only the train set, as shown in class. The reason is that we are pretending that the train data is all we have access to to fit our model fitting pipeline, so we cannot \"peek\" at the validation or test sets to generate our scaling. Use sklearn's StandardScaler (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to fit a scaling transform on the train set and transform the train set (you can use the fit_transform method on the train set).Then apply the fitted StandardScaler model to the validation and test sets as well (using the transform --- not the fit --- method). (Look at the notebook we went through in class on regularization and lasso if you are confused.) The transformed datasets are the final datasets you will feed into your logistic regression model. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b7f54a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train index values: [20555 10495 31081 ... 28547 20431 28351]\n",
      "val index values: [20555 10495 31081 ... 28547 20431 28351]\n",
      "test index values: [20555 10495 31081 ... 28547 20431 28351]\n"
     ]
    }
   ],
   "source": [
    "# get index values of all sets\n",
    "train_indexes = sqf_X_train.index.values\n",
    "val_indexes = sqf_X_val.index.values\n",
    "test_indexes = sqf_X_test.index.values\n",
    "\n",
    "# set set y values of all sets\n",
    "train_y_weapon = sample_data_dropped[\"found_weapon\"].loc[train_indexes]\n",
    "val_y_weapon = sample_data_dropped[\"found_weapon\"].loc[val_indexes]\n",
    "test_y_weapon = sample_data_dropped[\"found_weapon\"].loc[test_indexes]\n",
    "\n",
    "# check: print values of all sets \n",
    "print(\"train index values:\", sqf_X_train.index.values)\n",
    "print(\"val index values:\", sqf_X_train.index.values)\n",
    "print(\"test index values:\", sqf_X_train.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7fa0d2fc",
   "metadata": {
    "id": "FyVKwlbjgffV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit a scaling transform on the train set\n",
    "# source: lecture_7_regularization_and_lasso.ipynb by Emma Pierson \n",
    "\n",
    "# Use standardscaler to normalize the columns of our matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit_transform the trainset\n",
    "sqf_X_train = scaler.fit_transform(sqf_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8f53f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply fitted standard scaler to validation set, using the transform method\n",
    "\n",
    "sqf_X_val = scaler.transform(sqf_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3e73f7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# apply fitted standard scaler to test set, using the transform method\n",
    "\n",
    "sqf_X_test = scaler.transform(sqf_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8dfef6",
   "metadata": {
    "id": "involved-implement"
   },
   "source": [
    "e. Uisng sklearn.linear_model.LogisticRegression, fit a model on the train set to predict found_weapon. Set the \"penalty\" argument to \"none\" so that the model will not use any regularization; this corresponds to fitting a regular logistic regression model. If you get a `ConvergenceWarning`, increase the number of iterations using the `max_iter` argument; this means the model optimization needs more iterations to converge. (Look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) if you are uncertain which arguments to use!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27dd1061",
   "metadata": {
    "id": "ExHdN87ggimI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000, penalty='none')\n"
     ]
    }
   ],
   "source": [
    "# import logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# use logistic regression to fit a model on the train set to predit found_weapon\n",
    "lr = LogisticRegression(penalty=\"none\", max_iter=1000)\n",
    "\n",
    "# fit lr \n",
    "lr.fit(sqf_X_train, train_y_weapon) \n",
    "\n",
    "# check: print (for succesful output signal)\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0cc628f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02623576 0.55689095 0.0053888  ... 0.0430923  0.00631563 0.01780848]\n"
     ]
    }
   ],
   "source": [
    "# probabilty calculation found weapon false or true\n",
    "prob_weapon_train = lr.predict_proba(sqf_X_train)\n",
    "\n",
    "# split only to get true probability\n",
    "predic_true_weapon_train = lr.predict_proba(sqf_X_train)[:, 1]\n",
    "\n",
    "# check: print vales\n",
    "print(predic_true_weapon_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa997138",
   "metadata": {
    "id": "1Ep5iHbBhn1z"
   },
   "source": [
    "A standard measure of predictive performance for binary outcome variables like found_weapon is AUC. Higher values of AUC are better; an AUC of 1 means that the model is perfectly predicting the outcome; an AUC of 0.5 means that it is predicting it only as well as random chance. Report the AUC of the fitted model (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) on both the train and validation sets. What is the problem with using accuracy as a metric for this task? How does the train set AUC differ from the validation AUC, and does this make sense? (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "891ddb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8450438015962233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# train sets: give predic_true_weapon_train to roc function\n",
    "roc_auc_train = roc_auc_score(train_y_weapon, predic_true_weapon_train)\n",
    "\n",
    "print(roc_auc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "701d23c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701424028953051\n"
     ]
    }
   ],
   "source": [
    "# predict found_weapon: validation set\n",
    "\n",
    "lr = LogisticRegression(penalty=\"none\", max_iter=1000)\n",
    "\n",
    "# 1. fit\n",
    "lr.fit(sqf_X_val, val_y_weapon) \n",
    "\n",
    "# 2. predict\n",
    "prob_weapon_train = lr.predict_proba(sqf_X_val)\n",
    "\n",
    "# 3. split \n",
    "predic_true_weapon_val = lr.predict_proba(sqf_X_val)[:, 1]\n",
    "\n",
    "# 4. train\n",
    "roc_auc_val = roc_auc_score(val_y_weapon, predic_true_weapon_val)\n",
    "\n",
    "# 5. print\n",
    "print(roc_auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c3783",
   "metadata": {},
   "source": [
    "## Analyze: AUC (WIP 🛶)\n",
    "\n",
    "* What is the problem with using accuracy as a metric for this task? \n",
    "* How does the train set AUC differ from the validation AUC, and does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2397d7",
   "metadata": {
    "id": "eight-absorption"
   },
   "source": [
    "f. Our logistic regression model is not using any regularization and appears to be overfitting. We will try to use regularization to reduce overfitting. You will be fitting an L1-penalized logistic regression model using code that looks something like\n",
    "\n",
    "`LogisticRegression(C=sparsity_param, penalty='l1', solver='liblinear')`\n",
    "\n",
    "(the \"l1\" specifies that we're using an L1 penalty, as discussed in class; the \"liblinear\" solver is an optimizer that works with the L1 penalty. See the logistic regression documentation for more details.) \n",
    "\n",
    "Increase and decrease the amount of regularization using different values of the C parameter, searching logarithmically over at least 20 values in the range from 1e-2 to 1. (Note: we do not recommend defining a variable named \"C\" in your code, because this may cause weird patsy issues, since patsy also uses \"C\". Give the variable another name. Sorry! I complained to the patsy people.) \n",
    "\n",
    "Print out the train set, val set, and test set AUC for each value of of the regularization parameter. Make a plot where the x-axis is the regularization parameter and the y-axis is AUC, with one line for train AUC, one line for val AUC, and one line for test AUC (use plt.semilogx to plot the lines so the x-axis will be logarithmic, making it easier to see the plot). Comment on the trends. Do you see evidence of overfitting? Explain. For the rest of this assignment, use the model with the highest AUC on the validation set. (10 points)\n",
    "\n",
    "In a full analysis, it would make sense to play with other aspects of the model as well: for example, you could try using other forms of regularization (like L1 vs L2) or other classification algorithms besides logistic regression. The basic pattern, though, would be the same: fit the model on the train set, choose models on the val set, and once you've chosen your best model, assess your results (once!) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08949e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP 🛶\n",
    "\n",
    "# 1. write func/list that ranges > 20 values from 1e-2 to 1\n",
    "\n",
    "# 2. print out train, val and test set AUC for each val of the reg\n",
    "    # 2.1 define lr with: LogisticRegression(C=sparsity_param, penalty='l1', solver='liblinear'\n",
    "    # 2.2 assign each value from 1. sparsity_param to C\n",
    "\n",
    "# 3. make plot \n",
    "    # 3.1 x-axis are values from 1. and logarithmic (plt.semilogx)\n",
    "    # 3.2 y-axis is AUC\n",
    "    # 3.3 plot lines\n",
    "        # 3.3.1 line for train AUC\n",
    "        # 3.3.1 line for val AUC\n",
    "        # 3.3.1 line for test AUC\n",
    "    # 3.4 add legenda\n",
    "    # 3.5 style\n",
    "    \n",
    "# 4. analyze trends (text comments: overfitting? explain! and chose highest AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3021e54c",
   "metadata": {
    "id": "owMXSAmTeInj"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f7644d5",
   "metadata": {
    "id": "antique-connection"
   },
   "source": [
    "g. Assess model *calibration* on the test set. This checks whether the model's predicted probabilities line up with the true probabilities, and is important to assess here because we will be analyzing the model's predicted probabilities. To assess calibration, take the 10% of rows of the test set with the highest model predictions and compare the mean model predicted probability (ie, the output of `predict_proba`) to the actual mean of the outcome variable. Repeat for the next 10% of rows, and for all 10% groups. Make a plot comparing the model predicted probabilities on each 10% group to the actual outcomes (mean predicted probability on the x-axis and mean actual outcome on the y-axis). You should end up with a plot with 10 points, one for each 10% group. Plot the line y=x so you can see how well the predicted probabilities line up with the actual probabilities - ideally, your points will lie on the line or close to it. (10 points)\n",
    "\n",
    "Calibration is an issue for many machine learning models, including deep learning models, so this is always a good thing to check. In a full analysis, it would make sense to check calibration (and AUC) for subgroups as well (eg, each race group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d42d01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP 🛶\n",
    "\n",
    "# 1. write func(step (1,2,3 etc))\n",
    "    # 1.1 take 10% of rows in test set with highest model predictions \n",
    "    # 1.2 take mean model predicted (output of predict_proba)\n",
    "    # 1.3 compare 1. and 2. to the actual mean of the outcome variable (?where to get this?)\n",
    "\n",
    "# 2. loop over each 10% of rows and 10% groups (?what groups?) with func 1. \n",
    "\n",
    "# 3. make graph: \"model predicted probabilities VS actual outcomes\"\n",
    "    # 3.1 x-axis: mean predicted probability\n",
    "    # 3.2 y-axis: mean actual outcome\n",
    "    # 3.3 plot line: y=x (show: how well predicted prob line up with actual prob?)\n",
    "    # 3.4 style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259021f8",
   "metadata": {
    "id": "frozen-apollo"
   },
   "source": [
    "h. Using the test set, compute the fraction of observations which have lower than a 2% model-predicted probability of finding a weapon for Black, Hispanic, and white pedestrians. Stops below this threshold are extremely unlikely to have resulted in finding a weapon, arguably violating the Fourth Amendment. Repeat this for 20 thresholds evenly spaced between 1% and 5%. Make a graph where the x-axis is the threshold, and the y-axis is the fraction of stops falling below that threshold, with one line for each race group. Explain what you observe. Do you think this graph provides evidence for Fourteenth Amendment violations (racial discrimination)? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611377e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP 🛶\n",
    "\n",
    "# 1. funct(prob_para (2%, 3% etc)). \n",
    "    # 1.1 compute frac of observations % model-predicted probability of finding a weapon\n",
    "    # 1.2 for Black\n",
    "    # 1.3 for Hispanic\n",
    "    # 1.4 for white\n",
    "    \n",
    "# 2. repeat 1. for 20 thresholds evenly spaced between 1% and 5%\n",
    "\n",
    "# 3. make graph\n",
    "    # 3.1 x-axis: threshold\n",
    "    # 3.2 x-axis: fraction of stops falling below that threshold\n",
    "    # 3.3 plot lines\n",
    "        # 3.3.1 for Black\n",
    "        # 3.3.2 for Hispanic\n",
    "        # 3.3.3 for white\n",
    "\n",
    "# 4. analyze/observe (comment: provide evidence 14th amendment violations? Or racial discrimintation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f35b6",
   "metadata": {
    "id": "organized-luxembourg"
   },
   "source": [
    "i. The analysis you have performed in the second part of this assignment is very similar to the analysis in [this paper](https://5harad.com/papers/stop-and-frisk.pdf). Read the paper and write a few sentences about their main conclusions. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f1496",
   "metadata": {
    "id": "6wMU2Jzse3Dm"
   },
   "source": [
    "## Analyze: paper (WIP 🛶)\n",
    "\n",
    "* few sentences for their main conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4efed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
